{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9abf6f5f-3396-4285-89ec-4b1709f6553c",
   "metadata": {},
   "source": [
    "# MobileBERT for Question Answering on the SQuAD dataset\n",
    "\n",
    "### 2. Fine-tuning the model\n",
    "\n",
    "In these notebooks we are going use [MobileBERT implemented by HuggingFace](https://huggingface.co/docs/transformers/model_doc/mobilebert) on the question answering task by text-extraction on the [The Stanford Question Answering Dataset (SQuAD)](https://rajpurkar.github.io/SQuAD-explorer/). The data is composed by a set of questions and paragraphs that contain the answers. The model will be trained to locate the answer in the context by giving the positions where the answer starts and ends.\n",
    "\n",
    "In this notebook we are going to Fine-tuning the model.\n",
    "\n",
    "More info from HuggingFace docs:\n",
    "- [Question Answering](https://huggingface.co/tasks/question-answering)\n",
    "- [Glossary](https://huggingface.co/transformers/glossary.html#model-inputs)\n",
    "- [Question Answering chapter of NLP course](https://huggingface.co/learn/nlp-course/chapter7/7?fw=pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a9fef8-4780-4779-89de-662eb014d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, MobileBertForQuestionAnswering\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08765c80-6338-4dfa-97ce-cdd5adbc26af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.utils import disable_progress_bar\n",
    "from datasets import disable_caching\n",
    "\n",
    "\n",
    "disable_progress_bar()\n",
    "disable_caching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728089ed-5d62-491a-b623-d6928df88823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the tokenizer that was used for pretraining that model\n",
    "# We want to use https://huggingface.co/google/mobilebert-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26b500b-f80d-4e4e-940b-0076db7c5056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "# We will use the model MobileBertForQuestionAnswering that we imported on the first cell\n",
    "# Use this as reference\n",
    "# https://huggingface.co/docs/transformers/model_doc/mobilebert#transformers.MobileBertForPreTraining.forward.example\n",
    "model = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de5343b-999d-49ed-8565-e23aba38cd41",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "When instantiating model, there's a red message coming up. What does it mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0711c779-f6d0-4c6b-b127-286d8a4225fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ebb191-90f2-48e9-bf6c-80982682a893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing data\n",
    "# Include here all the preprocessing that was done on the notebook about exploring the dataset\n",
    "# and apply it via the dataset filter and the map \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c871cd-568c-4746-b26f-4fb8fecfb475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a PyTorch Dataloader for the train set\n",
    "# Use batch size 256 for a fast training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5e7095-724e-4653-88bc-74f283776de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model to the GPU 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec253c54-e224-4a4c-93ae-c61d6e833f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure model is in training mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e375d2f-d159-489f-b036-62332a64d0a4",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We are going to train for two epocs. We will use a different learning rate values in each epoch:\n",
    " - epoch 1: `lr = 2e-4` (to move fast on the loss function over the parameter space)\n",
    " - epoch 2: `lr = 2e-5` (to avoid jumping around and start converging towards a minimum)\n",
    "\n",
    "We will do this manually:\n",
    " - Run epoch one\n",
    " - Redifine the optimizer with the new learning rate and run again the training\n",
    "\n",
    "We should aim to loss values around 0.6, which will ensure \"decent\" predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f49addf3-f0f7-4262-913a-9710ead1d2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer using \"AdamW\" (Adam with decoupled weight decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874ae3c3-437b-48a6-9121-5bee67b78f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(loss):\n",
    "    \"\"\"Utility function for plotting\"\"\"\n",
    "\n",
    "    return loss.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb04b5ab-2714-4a0f-aede-179b1b20275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "\n",
    "for epoch in range(1):\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        ...  # reset automatic differentiation record\n",
    "        # evaluate the model and pass the output references (start_token_idx and end_token_idx)\n",
    "        outputs = model(input_ids=batch['input_ids'].to(device),\n",
    "                        token_type_ids=batch['token_type_ids'].to(device),\n",
    "                        attention_mask=batch['attention_mask'].to(device),\n",
    "                        start_positions=batch['start_token_idx'].to(device),\n",
    "                        end_positions=batch['end_token_idx'].to(device))        \n",
    "        loss = outputs[0]          # obtain the loss from the model output (specific of HugginFace's API)\n",
    "        history.append(log(loss))  # [not part of the traing] keep values for plotting later\n",
    "        ...    # Add the back propagation from the loss\n",
    "        ...    # update weights with the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6500b1-b2f0-4e2a-937e-2af917b59be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history, 'r-')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40befe5-9635-42c5-91d9-3baeafe76c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the mode to disk\n",
    "torch.save(model.state_dict(), 'mobilebertqa_ft')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a67584-b42d-403a-bc82-cd490843fb20",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "\n",
    "When your model is trained, run the notebook `3_mobilebert-squad-testing.ipynb` to test it on the validation set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
