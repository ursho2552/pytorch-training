0: [Rank 0] Dataset not found, downloading CIFAR-10...
0: [INFO] Dataset size: 50000 samples
0: [INFO] World size: 4 workers (data parallel)
0: [INFO] Global batch size: 256
0: [INFO] Local batch size per worker: 64
0: [INFO] Samples per worker per epoch: 12500
0: [Rank 0] Running in DDP mode with 4 processes
0: [1m[96m> global batch        0/    2940 [0m| elapsed time per batch (ms): 1770.0 | learning rate: 1.000E-03 |[92m loss: 147.34332[0m | memory used: 0.074 GB (peak 0.085 GB) | grad_norm: 6.66
0: [1m[96m> global batch       32/    2940 [0m| elapsed time per batch (ms): 2.9 | learning rate: 1.000E-03 |[92m loss: 116.16702[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 88.78
0: [1m[96m> global batch       64/    2940 [0m| elapsed time per batch (ms): 2.9 | learning rate: 1.000E-03 |[92m loss: 105.56116[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 182.23
0: [1m[96m> global batch       96/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 103.65006[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 117.71
0: [1m[96m> global batch      128/    2940 [0m| elapsed time per batch (ms): 3.2 | learning rate: 1.000E-03 |[92m loss: 91.70765[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 147.35
0: [1m[96m> global batch      160/    2940 [0m| elapsed time per batch (ms): 3.3 | learning rate: 1.000E-03 |[92m loss: 88.58986[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 129.08
0: [1m[96m> global batch      192/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 89.99400[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 124.43
0: [Epoch 1] Val Loss: 1.4294 | Accuracy: 47.07%  | Train Loss: 104.8555
0: [METRIC] epoch=1 time=4.09 val_loss=1.4294 acc=47.07 peak_mem=91MB
0: [1m[96m> global batch      224/    2940 [0m| elapsed time per batch (ms): 3.1 | learning rate: 1.000E-03 |[92m loss: 85.95825[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 259.84
0: [1m[96m> global batch      256/    2940 [0m| elapsed time per batch (ms): 3.1 | learning rate: 1.000E-03 |[92m loss: 85.08585[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 186.86
0: [1m[96m> global batch      288/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 83.74574[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 167.20
0: [1m[96m> global batch      320/    2940 [0m| elapsed time per batch (ms): 3.3 | learning rate: 1.000E-03 |[92m loss: 81.00381[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 239.62
0: [1m[96m> global batch      352/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 82.39372[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 120.00
0: [1m[96m> global batch      384/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 78.24857[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 165.31
0: [Epoch 2] Val Loss: 1.2411 | Accuracy: 55.03%  | Train Loss: 81.8824
0: [METRIC] epoch=2 time=2.20 val_loss=1.2411 acc=55.03 peak_mem=91MB
0: [1m[96m> global batch      416/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 84.84420[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 374.82
0: [1m[96m> global batch      448/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 74.20227[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 140.20
0: [1m[96m> global batch      480/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 74.08102[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 265.78
0: [1m[96m> global batch      512/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 68.37810[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 151.64
0: [1m[96m> global batch      544/    2940 [0m| elapsed time per batch (ms): 3.0 | learning rate: 1.000E-03 |[92m loss: 66.70093[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 240.60
0: [1m[96m> global batch      576/    2940 [0m| elapsed time per batch (ms): 2.9 | learning rate: 1.000E-03 |[92m loss: 75.87881[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 144.87
0: [Epoch 3] Val Loss: 1.0809 | Accuracy: 61.43%  | Train Loss: 71.1065
0: [METRIC] epoch=3 time=2.20 val_loss=1.0809 acc=61.43 peak_mem=91MB
0: [1m[96m> global batch      608/    2940 [0m| elapsed time per batch (ms): 2.9 | learning rate: 1.000E-03 |[92m loss: 65.26860[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 162.89
0: [1m[96m> global batch      640/    2940 [0m| elapsed time per batch (ms): 2.9 | learning rate: 1.000E-03 |[92m loss: 67.75443[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 125.25
0: [1m[96m> global batch      672/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 62.77403[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 274.80
0: [1m[96m> global batch      704/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 61.26289[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 166.33
0: [1m[96m> global batch      736/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 59.84867[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 183.52
0: [1m[96m> global batch      768/    2940 [0m| elapsed time per batch (ms): 3.0 | learning rate: 1.000E-03 |[92m loss: 63.38949[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 222.81
0: [Epoch 4] Val Loss: 1.0078 | Accuracy: 64.29%  | Train Loss: 63.8374
0: [METRIC] epoch=4 time=2.19 val_loss=1.0078 acc=64.29 peak_mem=91MB
0: [1m[96m> global batch      800/    2940 [0m| elapsed time per batch (ms): 3.1 | learning rate: 1.000E-03 |[92m loss: 59.42054[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 203.00
0: [1m[96m> global batch      832/    2940 [0m| elapsed time per batch (ms): 3.1 | learning rate: 1.000E-03 |[92m loss: 64.73151[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 235.95
0: [1m[96m> global batch      864/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 54.93686[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 221.62
0: [1m[96m> global batch      896/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 58.03777[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 216.94
0: [1m[96m> global batch      928/    2940 [0m| elapsed time per batch (ms): 2.9 | learning rate: 1.000E-03 |[92m loss: 57.01206[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 166.61
0: [1m[96m> global batch      960/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 60.18689[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 160.34
0: [Epoch 5] Val Loss: 1.0218 | Accuracy: 63.37%  | Train Loss: 58.2143
0: [METRIC] epoch=5 time=2.36 val_loss=1.0218 acc=63.37 peak_mem=91MB
0: [1m[96m> global batch      992/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 55.23176[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 217.20
0: [1m[96m> global batch     1024/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 53.16780[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 181.62
0: [1m[96m> global batch     1056/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 62.40002[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 265.08
0: [1m[96m> global batch     1088/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 60.36811[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 190.71
0: [1m[96m> global batch     1120/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 51.42957[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 203.18
0: [1m[96m> global batch     1152/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 51.38380[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 208.32
0: [Epoch 6] Val Loss: 0.9262 | Accuracy: 67.69%  | Train Loss: 53.8489
0: [METRIC] epoch=6 time=2.20 val_loss=0.9262 acc=67.69 peak_mem=91MB
0: [1m[96m> global batch     1184/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 44.43839[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 97.11
0: [1m[96m> global batch     1216/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 43.25467[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 124.69
0: [1m[96m> global batch     1248/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 58.41030[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 183.75
0: [1m[96m> global batch     1280/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 47.19700[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 147.84
0: [1m[96m> global batch     1312/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 43.53566[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 122.86
0: [1m[96m> global batch     1344/    2940 [0m| elapsed time per batch (ms): 3.0 | learning rate: 1.000E-03 |[92m loss: 47.10380[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 184.49
0: [Epoch 7] Val Loss: 0.8851 | Accuracy: 69.15%  | Train Loss: 49.4310
0: [METRIC] epoch=7 time=2.20 val_loss=0.8851 acc=69.15 peak_mem=91MB
0: [1m[96m> global batch     1376/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 45.41059[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 185.32
0: [1m[96m> global batch     1408/    2940 [0m| elapsed time per batch (ms): 3.2 | learning rate: 1.000E-03 |[92m loss: 45.79852[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 192.18
0: [1m[96m> global batch     1440/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 50.42611[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 187.24
0: [1m[96m> global batch     1472/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 46.68462[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 137.23
0: [1m[96m> global batch     1504/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 42.28749[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 168.43
0: [1m[96m> global batch     1536/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 45.90509[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 208.68
0: [Epoch 8] Val Loss: 0.8533 | Accuracy: 70.62%  | Train Loss: 45.1641
0: [METRIC] epoch=8 time=2.20 val_loss=0.8533 acc=70.62 peak_mem=91MB
0: [1m[96m> global batch     1568/    2940 [0m| elapsed time per batch (ms): 2.9 | learning rate: 1.000E-03 |[92m loss: 39.60773[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 138.64
0: [1m[96m> global batch     1600/    2940 [0m| elapsed time per batch (ms): 3.1 | learning rate: 1.000E-03 |[92m loss: 37.88667[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 178.77
0: [1m[96m> global batch     1632/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 44.76600[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 193.65
0: [1m[96m> global batch     1664/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 39.09228[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 166.00
0: [1m[96m> global batch     1696/    2940 [0m| elapsed time per batch (ms): 3.1 | learning rate: 1.000E-03 |[92m loss: 44.49212[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 166.26
0: [1m[96m> global batch     1728/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 39.86835[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 258.93
0: [1m[96m> global batch     1760/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 42.05823[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 183.48
0: [Epoch 9] Val Loss: 0.8375 | Accuracy: 71.23%  | Train Loss: 40.3797
0: [METRIC] epoch=9 time=2.20 val_loss=0.8375 acc=71.23 peak_mem=91MB
0: [1m[96m> global batch     1792/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 31.21139[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 152.21
0: [1m[96m> global batch     1824/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 36.49067[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 161.11
0: [1m[96m> global batch     1856/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 42.91667[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 158.63
0: [1m[96m> global batch     1888/    2940 [0m| elapsed time per batch (ms): 2.9 | learning rate: 1.000E-03 |[92m loss: 38.21375[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 245.49
0: [1m[96m> global batch     1920/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 38.92217[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 157.35
0: [1m[96m> global batch     1952/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 39.79639[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 187.08
0: [Epoch 10] Val Loss: 0.8506 | Accuracy: 71.26%  | Train Loss: 38.2028
0: [METRIC] epoch=10 time=2.20 val_loss=0.8506 acc=71.26 peak_mem=91MB
0: [1m[96m> global batch     1984/    2940 [0m| elapsed time per batch (ms): 3.0 | learning rate: 1.000E-03 |[92m loss: 26.67360[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 122.56
0: [1m[96m> global batch     2016/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 32.89624[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 169.83
0: [1m[96m> global batch     2048/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 29.69081[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 153.51
0: [1m[96m> global batch     2080/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 31.22937[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 129.28
0: [1m[96m> global batch     2112/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 34.80624[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 149.97
0: [1m[96m> global batch     2144/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 35.19635[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 229.61
0: [Epoch 11] Val Loss: 0.8742 | Accuracy: 71.08%  | Train Loss: 34.1725
0: [METRIC] epoch=11 time=2.20 val_loss=0.8742 acc=71.08 peak_mem=91MB
0: [1m[96m> global batch     2176/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 32.90502[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 183.37
0: [1m[96m> global batch     2208/    2940 [0m| elapsed time per batch (ms): 2.9 | learning rate: 1.000E-03 |[92m loss: 30.59733[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 187.09
0: [1m[96m> global batch     2240/    2940 [0m| elapsed time per batch (ms): 3.0 | learning rate: 1.000E-03 |[92m loss: 31.51779[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 147.81
0: [1m[96m> global batch     2272/    2940 [0m| elapsed time per batch (ms): 3.2 | learning rate: 1.000E-03 |[92m loss: 26.69069[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 176.34
0: [1m[96m> global batch     2304/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 29.55554[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 139.22
0: [1m[96m> global batch     2336/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 31.83862[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 133.73
0: [Epoch 12] Val Loss: 0.8910 | Accuracy: 71.32%  | Train Loss: 31.2730
0: [METRIC] epoch=12 time=2.20 val_loss=0.8910 acc=71.32 peak_mem=91MB
0: [1m[96m> global batch     2368/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 29.34926[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 155.49
0: [1m[96m> global batch     2400/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 23.96535[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 190.15
0: [1m[96m> global batch     2432/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 27.41567[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 172.72
0: [1m[96m> global batch     2464/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 28.15328[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 259.51
0: [1m[96m> global batch     2496/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 26.19829[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 138.35
0: [1m[96m> global batch     2528/    2940 [0m| elapsed time per batch (ms): 3.0 | learning rate: 1.000E-03 |[92m loss: 32.63645[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 208.04
0: [Epoch 13] Val Loss: 0.8649 | Accuracy: 72.71%  | Train Loss: 27.0548
0: [METRIC] epoch=13 time=2.20 val_loss=0.8649 acc=72.71 peak_mem=91MB
0: [1m[96m> global batch     2560/    2940 [0m| elapsed time per batch (ms): 2.9 | learning rate: 1.000E-03 |[92m loss: 22.72154[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 134.35
0: [1m[96m> global batch     2592/    2940 [0m| elapsed time per batch (ms): 3.2 | learning rate: 1.000E-03 |[92m loss: 17.11601[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 135.40
0: [1m[96m> global batch     2624/    2940 [0m| elapsed time per batch (ms): 3.0 | learning rate: 1.000E-03 |[92m loss: 24.67245[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 133.22
0: [1m[96m> global batch     2656/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 27.74479[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 128.74
0: [1m[96m> global batch     2688/    2940 [0m| elapsed time per batch (ms): 2.9 | learning rate: 1.000E-03 |[92m loss: 18.63818[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 119.75
0: [1m[96m> global batch     2720/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 27.90087[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 160.29
0: [Epoch 14] Val Loss: 0.9498 | Accuracy: 71.74%  | Train Loss: 23.4968
0: [METRIC] epoch=14 time=2.20 val_loss=0.9498 acc=71.74 peak_mem=91MB
0: [1m[96m> global batch     2752/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 21.48668[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 149.77
0: [1m[96m> global batch     2784/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 25.19019[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 201.34
0: [1m[96m> global batch     2816/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 19.78128[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 154.86
0: [1m[96m> global batch     2848/    2940 [0m| elapsed time per batch (ms): 2.8 | learning rate: 1.000E-03 |[92m loss: 16.45182[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 138.17
0: [1m[96m> global batch     2880/    2940 [0m| elapsed time per batch (ms): 2.7 | learning rate: 1.000E-03 |[92m loss: 20.50995[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 150.61
0: [1m[96m> global batch     2912/    2940 [0m| elapsed time per batch (ms): 2.9 | learning rate: 1.000E-03 |[92m loss: 20.53890[0m | memory used: 0.074 GB (peak 0.089 GB) | grad_norm: 150.20
0: [1m[96m> global batch     2939/    2940 [0m| elapsed time per batch (ms): 3.0 | learning rate: 1.000E-03 |[92m loss: 8.41442[0m | memory used: 0.073 GB (peak 0.089 GB) | grad_norm: 90.73
0: [Epoch 15] Val Loss: 0.9722 | Accuracy: 71.88%  | Train Loss: 21.0734
0: [METRIC] epoch=15 time=2.20 val_loss=0.9722 acc=71.88 peak_mem=91MB
